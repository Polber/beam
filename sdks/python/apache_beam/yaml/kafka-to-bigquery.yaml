template:

  name: "Kafka_To_BigQuery_Yaml"
  display_name: "Kafka TO BigQuery (Yaml)"
  description: "A template for Kafka to BigQuery."

  parameters:
    - name: "kafkaReadTopics"
      help: "Kafka topic to read the input from."
      required: true

    - name: "messageFormat"
      help: "Format of Kafka message data. One of: RAW, JSON, AVRO, PROTO."
      required: true

    - name: "schemaPath"
      help: "Kafka schema. A schema is required if data format is JSON, AVRO or PROTO."
      required: false

    - name: "readBootstrapServers"
      help: "Kafka Bootstrap Server list, separated by commas."
      required: false

    - name: "outputTableSpec"
      help: "BigQuery table location to write the output to."
      required: true

    - name: "outputDeadletterTable"
      help: "The dead-letter table name to output failed messages to BigQuery."
      required: true

    - name: "numStorageWriteApiStreams"
      help: "Number of streams defines the parallelism of the BigQueryIOâ€™s Write."
      required: false

pipeline:
  transforms:
    - type: ReadFromKafka
      config:
        schema: $schemaPath
        format: $messageFormat
        topic: $kafkaReadTopics
        bootstrap_servers: $readBootstrapServers
    - type: WriteToBigQuery
      name: WriteGoodMessages
      input: ReadFromKafka
      config:
        table: $outputTableSpec
        num_streams: $numStorageWriteApiStreams
        error_handling:
          output: errors
    - type: WriteToBigQuery
      name: WriteBadMessages
      input: WriteGoodMessages.errors
      config:
        table: $outputDeadletterTable
        num_streams: $numStorageWriteApiStreams
